# -*- coding: utf-8 -*-
"""Final Project Version 2

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JH0iWmFDyXNwi0BUxBxAxNTn5AHr5lRG
"""

#Mount Google drive
from google.colab import drive
drive.mount('/content/gdrive')

#Since the file is a zip file this is needed in order to unzip the file
import zipfile

zip_path = '/content/gdrive/MyDrive/CS471/DataForAssignment/zoo.zip'
extract = '/content/'

with zipfile.ZipFile(zip_path,'r') as zip_ref:
  zip_ref.extractall(extract)

!ls /content/
!ls /content/zoo.data
!ls /content/zoo.names

#all the imports that will be used as the program goes on
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sb
import numpy as np

from sklearn import metrics
from sklearn.metrics import mean_squared_error,accuracy_score,classification_report
from sklearn.model_selection import train_test_split

#Grab the data from the drive
zoo = pd.read_csv('/content/zoo.data',header = None)

"""Prepare the data:
  1. Data Cleaning
  2. Feature Engineering
"""

labels = ['animal_name','hair','feathers','eggs','milk','airborne','aquatic','predator','toothed',
              'backbone','breathes','venomous','fins','legs','tail','domestic','catsize','type']
#Show the data
zoo.columns = labels
zoo.head()

zoo.drop("animal_name",axis = 1,inplace = True)

#Experiment #1 - Attempting to change object into int or float
#zoo['animal_name'].astype(str).astype(float)

# Get the info for the varaiables
zoo.info()

# Show all the current attributes
# 0 represents a NO output
# 1 represents a YES output
import matplotlib.pyplot as plt
zoo.hist(bins = 40, figsize = (11,11))

plt.xticks([0,1])
plt.show()

corr_matrix = zoo.corr()
corr_matrix['hair'].sort_values(ascending = False)

#Count the predators with legs
predator = zoo[zoo['predator'] == 1]
Number_of_legs = zoo['legs'].value_counts()

#Get the legs
values = Number_of_legs.index
predator_count = Number_of_legs.values

#plot the points
plt.bar(values,predator_count)
plt.ylim(0,50)
plt.xticks(range(0,9))
plt.xlabel('# of Legs')
plt.ylabel('# of Predators')
plt.show()

#Count the predators with legs
predator = zoo[zoo['predator'] == 1]
toothed = zoo['toothed'].value_counts()

#Get the legs
values = toothed.index
toothed_count = toothed.values

preadtor = zoo['predator'].value_counts()
print(toothed,' ', preadtor)

#plot the points
plt.bar(values,toothed_count)
plt.ylim(0,65)
plt.xlim('No','Yes')
plt.xticks([0,1])
plt.xlabel('Toothed')
plt.ylabel('# of Predators')
plt.show()

zoo.head()

#Feature Scaling
from sklearn.preprocessing import MinMaxScaler

#Used to scale down the range for outliers while doing it towards each feature individually
min_max_scaler = MinMaxScaler(feature_range=(0,1))
zoo_data_scaled = min_max_scaler.fit_transform(zoo)
print(zoo_data_scaled)

#Data Splitting

X = zoo.drop(["type"],axis = 1) #train on all the data except for the type
y = zoo["type"] # The Y or testing set will be on the type/target column

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3, random_state = 1) # 70 on training and 30% on test

"""Algorithms:
  1. Random Forest
  2. K Nearest Neighbor
"""

#Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier

# Set the model that we want to use
RFC = RandomForestClassifier()

# Fit the model with training set
RFC = RFC.fit(X_train,y_train)

# Predict the accuracy with the testing set
y_pred = RFC.predict(X_test)

# Get the accuracy
acc_score = metrics.accuracy_score(y_test,y_pred) * 100

# Print the current accuracy that we got
print("Accuracy:", acc_score, '%')

#Import the K nearest neighbor for the classification problem
from sklearn.neighbors import KNeighborsClassifier

# n_neighbors how many points we want to use
# Weights gives us how we want the nearest points to be considered
# - Either Uniformly where all points are equal
# - Distance where the closest points have more influence
# Metric will describe which distance formula we want to use to get the points
KNC = KNeighborsClassifier(n_neighbors = 5,weights = 'distance', metric = 'euclidean')
KNC = KNC.fit(X_train,y_train)

# Predict the accuracy using K nearest neighbor
KNC_pred = KNC.predict(X_test)

KNN_acc_score = metrics.accuracy_score(y_test,y_pred) * 100

# Print the current accuracy that we got
print("Accuracy:", KNN_acc_score, '%')

"""Tuning/Model Comparison"""

# Randomized Search to get the best hyperparameters
from sklearn.model_selection import RandomizedSearchCV
from sklearn.pipeline import Pipeline

# Pipeline for the parameters
full_pipeline = Pipeline([("random_forest",RandomForestClassifier(random_state= 20))])

# Hyperparameters to tune
params = {'max_depth':[5,10,15],
          'max_features':[3,5,7],
          'n_estimators':[1,2,50],
          'max_samples':[0.2,0.5,0.8]
          }

# Get the list of all possible hyper parameters
full_pipeline.get_params().keys()

# estimator is the model
# param_distributions is the hyper parameters that we are tuning
# n_iter is the number of parameter to sample
RSC_search = RandomizedSearchCV(estimator = RFC, param_distributions = params, n_iter = 8,random_state = 20)

RSC_search.fit(X_train,y_train)

RSC_best_model = RSC_search.best_estimator_
RSC_best_pred = RSC_best_model.predict(X_test)
RSC_best_acc_score = metrics.accuracy_score(y_test,RSC_best_pred) * 100

# Print the current accuracy that we got
print("Accuracy:", RSC_best_acc_score, '%')

#Classification Report
print("Classification Report:\n",classification_report(y_test,RSC_best_pred))

# Randomized Search to get the best hyperparameters
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline

# Pipeline for the parameters
full_pipeline = Pipeline(["random_forest",RandomForestClassifier()])

# Hyperparameters to tune
grid_params = {'max_depth':[5,10,15],
          'max_features':[3,5,7],
          'n_estimators':[1,2,50],
          'max_samples':[0.2,0.5,0.8]
          }


# Grid Search tuning
RFC_Grid_search = GridSearchCV(estimator = RandomForestClassifier(),param_grid = grid_params,cv = 3)

RFC_Grid_search.fit(X_train,y_train)

RFC_Grid_best_model = RFC_Grid_search.best_estimator_
RFC_Grid_best_pred = RFC_Grid_best_model.predict(X_test)
RFC_Grid_best_acc_score = metrics.accuracy_score(y_test,RFC_Grid_best_pred) * 100

# Print the current accuracy that we got
print("Accuracy:", RFC_Grid_best_acc_score, '%')

# Classification Report
print("Classification Report:\n",classification_report(y_test,RFC_Grid_best_pred))